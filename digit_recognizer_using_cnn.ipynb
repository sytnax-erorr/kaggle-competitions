{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "digit-recognizer-using-cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "IalYnu5IoQsD",
        "colab_type": "code",
        "colab": {},
        "outputId": "6ac4a9c7-edc6-4c4d-9034-2513401c4062"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np # Linear algebra\n",
        "import pandas as pd # For data manipulation\n",
        "import matplotlib.pyplot as plt # For visualization\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import StratifiedKFold # For evaluation and hyperparameter tuning\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix, classification_report # For evaluation\n",
        "from scipy.ndimage import rotate, shift, zoom # For data augmentation\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from IPython.display import FileLink # For downloading the output file\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/kaggle/input/digit-recognizer/train.csv\n",
            "/kaggle/input/digit-recognizer/test.csv\n",
            "/kaggle/input/digit-recognizer/sample_submission.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "W54j82R8oQsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading the datasets into dataframes\n",
        "train_df = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\n",
        "test_df = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\n",
        "submission_df = pd.read_csv(\"/kaggle/input/digit-recognizer/sample_submission.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1XvWGKVoQs6",
        "colab_type": "code",
        "colab": {},
        "outputId": "380b8d12-7251-4921-e67e-b549ed81aaa5"
      },
      "source": [
        "# Converting the train and test dataframes into numpy arrays\n",
        "X_train = train_df.iloc[:, 1:].values\n",
        "y_train = train_df.iloc[:, 0].values\n",
        "X_test = test_df.values\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (42000, 784)\n",
            "y_train shape: (42000,)\n",
            "X_test shape: (28000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgLBzd5NoQtG",
        "colab_type": "code",
        "colab": {},
        "outputId": "39190d4c-eb53-4c82-8c86-8539bb635482"
      },
      "source": [
        "# Visualizing a digit from the training data as a 28 X 28 image\n",
        "some_digit = X_train[40]\n",
        "\n",
        "some_digit_image = some_digit.reshape(28, 28)\n",
        "print(f\"Label: {y_train[40]}\")\n",
        "plt.imshow(some_digit_image, cmap=\"binary\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADgxJREFUeJzt3W2MVHWWx/HfkQchMi8gNA8R3GYnRFdJBjYlMdEYN4PEIUREMwZIJqwZp0czmiUZ4yJv8CEbycaZWQ2bMc3aDhoQSGYEXpjZIT5Ex2xGS2PQGXTbmN4BabuboJkeoiEtZ1/07UmLXf8qqm7VrfZ8Pwmpqnvu7XtS9K/vrfrfqr+5uwDEc1HRDQAoBuEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxDU1FbubO7cud7Z2dnKXQKh9PX16dSpU1bLug2F38xukvS4pCmS/svdd6TW7+zsVLlcbmSXABJKpVLN69Z92m9mUyT9p6TvSbpS0kYzu7LenwegtRp5zb9S0ofu/pG7n5W0T9K6fNoC0GyNhP9SScfHPT6RLfsKM+sys7KZlYeGhhrYHYA8NRL+id5U+Nrng929291L7l7q6OhoYHcA8tRI+E9IWjzu8SJJJxtrB0CrNBL+NyUtNbMlZjZd0gZJh/NpC0Cz1T3U5+4jZnaPpP/W6FBfj7v/MbfOADRVQ+P87v6CpBdy6gVAC3F5LxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0E1NEuvmfVJGpb0paQRdy/l0RTyc/DgwWS9t7c3WX/00UeT9WnTpiXr9913X8XaVVddldx2zZo1yToa01D4M//k7qdy+DkAWojTfiCoRsPvkn5nZm+ZWVceDQFojUZP+69195NmNk/SETN7391fHb9C9kehS5Iuu+yyBncHIC8NHfnd/WR2OyjpeUkrJ1in291L7l7q6OhoZHcAclR3+M3sEjP71th9SaslvZdXYwCaq5HT/vmSnjezsZ+z191/m0tXAJqu7vC7+0eSvpNjL6ig2lj89u3bK9aqjfOPjIwk61Onpn9Fvvjii2T9/vvvr1ibNWtWctsDBw4k66tXr07Wp0yZkqxHx1AfEBThB4Ii/EBQhB8IivADQRF+IKg8PtWHBp06lf5Q5B133JGsv/766xVrCxYsSG77yiuvJOuXX355sl7N3XffXbH25JNPJret9pHeXbt2Jet33nlnsh4dR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIpx/jZw5syZZD01jl9NT09Pst7oOH41Dz30UMXap59+mtx2//79yfrx48fr6gmjOPIDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM87eBmTNnJutz585N1lPfB/DZZ5/V1VNe5s2bV7G2atWq5LaHDh1K1m+77ba6esIojvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFTVcX4z65G0VtKguy/Lls2RtF9Sp6Q+Sbe7e/rD2agoNRYuSStWrEjWjxw5UrG2Y8eO5LaDg4PJ+l133ZWsf/LJJ8n6nj17KtYefvjh5LbTpk1L1qtdH4G0Wo78v5J003nLtkp60d2XSnoxewxgEqkafnd/VdLp8xavk7Q7u79b0i059wWgyep9zT/f3fslKbtNn7cCaDtNf8PPzLrMrGxm5aGhoWbvDkCN6g3/gJktlKTstuK7Ru7e7e4ldy91dHTUuTsAeas3/Iclbc7ub5aU/vgVgLZTNfxm9pyk/5F0uZmdMLMfStoh6UYz65V0Y/YYwCRSdZzf3TdWKH03515QwZIlS+re9ujRo8n6li1bkvW9e/cm62+88cYF91SrTZs2JetLly5t2r4j4Ao/ICjCDwRF+IGgCD8QFOEHgiL8QFB8dfcksHPnzmR9eHi4Yu3ll19OblvtI7nVhvKuuOKKZD11Vedrr72W3HbRokXJOhrDkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmKcfxKo9hXWqY/dDgwMJLft7e2tq6cx1113XbLe1dVVsVZtnB/NxZEfCIrwA0ERfiAowg8ERfiBoAg/EBThB4JinP8bbv78+Q3VGzV79uym/nzUjyM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRVdZzfzHokrZU06O7LsmUPSvqRpKFstW3u/kKzmsTkdejQoaJbQAW1HPl/JemmCZb/wt2XZ/8IPjDJVA2/u78q6XQLegHQQo285r/HzI6aWY+ZcQ0nMMnUG/5fSvq2pOWS+iX9rNKKZtZlZmUzKw8NDVVaDUCL1RV+dx9w9y/d/ZykXZJWJtbtdveSu5dSkzYCaK26wm9mC8c9XC/pvXzaAdAqtQz1PSfpBklzzeyEpO2SbjCz5ZJcUp+kHzexRwBNUDX87r5xgsVPNaEX4CsWLFhQdAvfaFzhBwRF+IGgCD8QFOEHgiL8QFCEHwiKr+6eBM6ePZusT58+vUWdtNbatWuLbuEbjSM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOH8b+Pzzz5P1Bx54IFl/7LHHKtamTm3f/+I5c+Yk6zNmzGhRJzFx5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoNp3EDiQp59+OllfvHhxsn7RRcX9DX///feT9dQUbddff31y23nz5tXVE2rDkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgqo6zm9miyU9I2mBpHOSut39cTObI2m/pE5JfZJud/dPm9fqN9cjjzySrO/evTtZb+Y4/8jISLK+atWqZP306dMVa5s2baqrJ+Sjlt+aEUk/dfd/kHSNpJ+Y2ZWStkp60d2XSnoxewxgkqgafnfvd/e3s/vDko5JulTSOkljh6Tdkm5pVpMA8ndB54tm1ilphaQ/SJrv7v3S6B8ISVyLCUwiNYffzGZJ+rWkLe7+lwvYrsvMymZWTl3nDaC1agq/mU3TaPD3uPtvssUDZrYwqy+UNDjRtu7e7e4ldy91dHTk0TOAHFQNv5mZpKckHXP3n48rHZa0Obu/WdKh/NsD0Cy1fKT3Wkk/kPSumb2TLdsmaYekA2b2Q0l/lvT95rQ4+R07dixZHx4eTtY/+OCDZH316tUX3NOYai/Fenp6kvWPP/44WV+/fn3F2s0335zcFs1VNfzu/ntJVqH83XzbAdAqXOEHBEX4gaAIPxAU4QeCIvxAUIQfCIqv7m6BJ554Ilk/c+ZMsv7SSy8l6ytXrqxY6+3tTW67dWv6w5jVxvGvueaaZH3nzp0VaxdffHFyWzQXR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIpx/hbo7+9vaPuDBw8m64cPH65YO3fuXHLbGTNmJOsbNmxI1p999tlkfepUfsXaFUd+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKQdgWuPfee5P1mTNnJuv79u1L1q+++uqKtVtvvTW57Zo1a5L1ZcuWJeuYvDjyA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQ5u7pFcwWS3pG0gJJ5yR1u/vjZvagpB9JGpvgfZu7v5D6WaVSycvlcsNNA5hYqVRSuVy2Wtat5SKfEUk/dfe3zexbkt4ysyNZ7Rfu/li9jQIoTtXwu3u/pP7s/rCZHZN0abMbA9BcF/Sa38w6Ja2Q9Ids0T1mdtTMesxsdoVtusysbGbloaGhiVYBUICaw29msyT9WtIWd/+LpF9K+rak5Ro9M/jZRNu5e7e7l9y91NHRkUPLAPJQU/jNbJpGg7/H3X8jSe4+4O5fuvs5SbskVZ4tEkDbqRp+MzNJT0k65u4/H7d84bjV1kt6L//2ADRLLe/2XyvpB5LeNbN3smXbJG00s+WSXFKfpB83pUMATVHLu/2/lzTRuGFyTB9Ae+MKPyAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFBVv7o7152ZDUn6v3GL5ko61bIGLky79taufUn0Vq88e/s7d6/p+/JaGv6v7dys7O6lwhpIaNfe2rUvid7qVVRvnPYDQRF+IKiiw99d8P5T2rW3du1Lord6FdJboa/5ARSn6CM/gIIUEn4zu8nMPjCzD81saxE9VGJmfWb2rpm9Y2aFTimcTYM2aGbvjVs2x8yOmFlvdjvhNGkF9fagmX2cPXfvmNmagnpbbGYvm9kxM/ujmf1LtrzQ5y7RVyHPW8tP+81siqT/lXSjpBOS3pS00d3/1NJGKjCzPkkldy98TNjMrpf0V0nPuPuybNm/Szrt7juyP5yz3f1f26S3ByX9teiZm7MJZRaOn1la0i2S/lkFPneJvm5XAc9bEUf+lZI+dPeP3P2spH2S1hXQR9tz91clnT5v8TpJu7P7uzX6y9NyFXprC+7e7+5vZ/eHJY3NLF3oc5foqxBFhP9SScfHPT6h9pry2yX9zszeMrOuopuZwPxs2vSx6dPnFdzP+arO3NxK580s3TbPXT0zXuetiPBPNPtPOw05XOvu/yjpe5J+kp3eojY1zdzcKhPMLN0W6p3xOm9FhP+EpMXjHi+SdLKAPibk7iez20FJz6v9Zh8eGJskNbsdLLifv2mnmZsnmllabfDctdOM10WE/01JS81siZlNl7RB0uEC+vgaM7skeyNGZnaJpNVqv9mHD0vanN3fLOlQgb18RbvM3FxpZmkV/Ny124zXhVzkkw1l/IekKZJ63P3fWt7EBMzs7zV6tJdGJzHdW2RvZvacpBs0+qmvAUnbJR2UdEDSZZL+LOn77t7yN94q9HaDRk9d/zZz89hr7Bb3dp2k1yS9K+lctnibRl9fF/bcJfraqAKeN67wA4LiCj8gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0H9P57h8VcII9jHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzrPt3kYoQtR",
        "colab_type": "text"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4NIS_2IoQtV",
        "colab_type": "code",
        "colab": {},
        "outputId": "9648707f-e7ac-45cd-f1e9-a1d347d541dc"
      },
      "source": [
        "def shift_in_one_direction(image, direction):\n",
        "    \"\"\"\n",
        "    Shifts an image by one pixel in the specified direction\n",
        "    \"\"\"\n",
        "    if direction == \"DOWN\":\n",
        "        image = shift(image, [1, 0])\n",
        "    elif direction == \"UP\":\n",
        "        image = shift(image, [-1, 0])\n",
        "    elif direction == \"LEFT\":\n",
        "        image = shift(image, [0, -1])\n",
        "    else:\n",
        "        image = shift(image, [0, 1])\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def shift_in_all_directions(image):\n",
        "    \"\"\"\n",
        "    Shifts an image in all the directions by one pixel\n",
        "    \"\"\"\n",
        "    reshaped_image = image.reshape(28, 28)\n",
        "\n",
        "    down_shifted_image = shift_in_one_direction(reshaped_image, \"DOWN\")\n",
        "    up_shifted_image = shift_in_one_direction(reshaped_image, \"UP\")\n",
        "    left_shifted_image = shift_in_one_direction(reshaped_image, \"LEFT\")\n",
        "    right_shifted_image = shift_in_one_direction(reshaped_image, \"RIGHT\")\n",
        "\n",
        "    return (down_shifted_image, up_shifted_image,\n",
        "            left_shifted_image, right_shifted_image)\n",
        "\n",
        "\n",
        "def rotate_in_all_directions(image, angle):\n",
        "    \"\"\"\n",
        "    Rotates an image clockwise and anti-clockwise\n",
        "    \"\"\"\n",
        "    reshaped_image = image.reshape(28, 28)\n",
        "    \n",
        "    rotated_images = (rotate(reshaped_image, angle, reshape=False),\n",
        "                      rotate(reshaped_image, -angle, reshape=False))\n",
        "    \n",
        "    return rotated_images\n",
        "\n",
        "\n",
        "def clipped_zoom(image, zoom_ranges):\n",
        "    \"\"\"\n",
        "    Clips and zooms an image at the specified zooming ranges\n",
        "    \"\"\"\n",
        "    reshaped_image = image.reshape(28, 28)\n",
        "    \n",
        "    h, w = reshaped_image.shape\n",
        "    \n",
        "    zoomed_images = []\n",
        "    for zoom_range in zoom_ranges:\n",
        "        zh = int(np.round(h / zoom_range))\n",
        "        zw = int(np.round(w / zoom_range))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "        \n",
        "        zoomed_images.append(zoom(reshaped_image[top:top+zh, left:left+zw],\n",
        "                                  zoom_range))\n",
        "    \n",
        "    return zoomed_images\n",
        "\n",
        "def alter_image(image):\n",
        "    \"\"\"\n",
        "    Alters an image by shifting, rotating, and zooming it\n",
        "    \"\"\"\n",
        "    shifted_images = shift_in_all_directions(image)\n",
        "    rotated_images = rotate_in_all_directions(image, 10)\n",
        "    zoomed_images = clipped_zoom(image, [1.1, 1.2])\n",
        "            \n",
        "    return np.r_[shifted_images, rotated_images, zoomed_images]\n",
        "\n",
        "X_train_add = np.apply_along_axis(alter_image, 1, X_train).reshape(-1, 784)\n",
        "y_train_add = np.repeat(y_train, 8)\n",
        "\n",
        "print(f\"X_train_add shape: {X_train_add.shape}\")\n",
        "print(f\"y_train_add shape: {y_train_add.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_add shape: (336000, 784)\n",
            "y_train_add shape: (336000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIr4rLE_oQtf",
        "colab_type": "text"
      },
      "source": [
        "Combining the original images and the synthesized images to form a new dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOy_f-cHoQth",
        "colab_type": "code",
        "colab": {},
        "outputId": "744ff7d7-a22e-4486-e817-af2bf1859eb2"
      },
      "source": [
        "# Combining the original images and the synthesized images\n",
        "X_train_combined = np.r_[X_train, X_train_add]\n",
        "y_train_combined = np.r_[y_train, y_train_add]\n",
        "\n",
        "del X_train\n",
        "del X_train_add\n",
        "del y_train\n",
        "del y_train_add\n",
        "\n",
        "print(f\"X_train_combined shape: {X_train_combined.shape}\")\n",
        "print(f\"y_train_combined shape: {y_train_combined.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_combined shape: (378000, 784)\n",
            "y_train_combined shape: (378000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1h_5JIHoQtq",
        "colab_type": "text"
      },
      "source": [
        "### Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO33qj8moQtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageReshaper(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Reshapes the data to the shape required by the KerasClassifier\n",
        "    \"\"\"\n",
        "    def __init__(self, shape):\n",
        "        self.shape = shape\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        return X.reshape(self.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--OVQtJzoQt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to build a model based on LeNet-5 architecture\n",
        "\n",
        "def build_lenet5_model():\n",
        "    \"\"\"\n",
        "    Builds and returns the model based on LeNet-5 architecture\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    # Adding layers to the model\n",
        "    model.add(Conv2D(6, kernel_size=5, activation='relu',\n",
        "                     input_shape=(28,28,1)))\n",
        "    model.add(MaxPooling2D())\n",
        "    \n",
        "    model.add(Conv2D(16, kernel_size=5, activation='relu'))\n",
        "    model.add(MaxPooling2D())\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    \n",
        "    model.add(Dense(400, activation='relu'))\n",
        "    model.add(Dense(120, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    # Specifying the loss function and optimizer\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F76vdN5oQuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to build a model based on a modified LeNet-5 architecture from the above mentioned notebook\n",
        "\n",
        "def build_custom_lenet5_model():\n",
        "    \"\"\"\n",
        "    Builds and returns the model based on a modified LeNet-5 architecture\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    # Adding layers to the model\n",
        "    model.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(28,28,1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32,kernel_size=3,activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    # Specifying the loss function and optimizer\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "id": "t5dGHuF2oQuQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "3b29dc12-2eac-49f0-ae76-00cc341d7996"
      },
      "source": [
        "stratified_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, indices in enumerate(stratified_fold.split(X_train_combined, y_train_combined)):\n",
        "    # Creating datasets for training and testing the model \n",
        "    X_train_, y_train_ = X_train_combined[indices[0]], y_train_combined[indices[0]]\n",
        "    X_test_, y_test_ = X_train_combined[indices[1]], y_train_combined[indices[1]]\n",
        "    \n",
        "    model_pipeline = Pipeline([\n",
        "        ('min_max_scaler', MinMaxScaler()),\n",
        "        ('image_reshaper', ImageReshaper(shape=(-1, 28, 28, 1))),\n",
        "        ('model', KerasClassifier(build_lenet5_model, epochs=5, batch_size=32))\n",
        "    ])\n",
        "    \n",
        "    model_pipeline.fit(X_train_, y_train_)\n",
        "    predictions = model_pipeline.predict(X_test_)\n",
        "    \n",
        "    print(f\"Classification report for Fold {fold + 1}:\")\n",
        "    print(classification_report(y_test_, predictions, digits=3), end=\"\\n\\n\")\n",
        "    \n",
        "    print(f\"Confusion Matrix for Fold {fold + 1}:\")\n",
        "    print(confusion_matrix(y_test_, predictions), end=\"\\n\\n\")\n",
        "    \n",
        "    del X_train_\n",
        "    del X_test_\n",
        "    del y_train_\n",
        "    del y_test_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "302400/302400 [==============================] - 49s 160us/step - loss: 0.0782 - accuracy: 0.9753\n",
            "Epoch 2/5\n",
            "302400/302400 [==============================] - 44s 147us/step - loss: 0.0262 - accuracy: 0.9917\n",
            "Epoch 3/5\n",
            "302400/302400 [==============================] - 44s 145us/step - loss: 0.0187 - accuracy: 0.9942\n",
            "Epoch 4/5\n",
            "302400/302400 [==============================] - 45s 149us/step - loss: 0.0147 - accuracy: 0.9955\n",
            "Epoch 5/5\n",
            "302400/302400 [==============================] - 45s 149us/step - loss: 0.0123 - accuracy: 0.9960\n",
            "Classification report for Fold 1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.997     0.997     0.997      7437\n",
            "           1      0.998     0.993     0.996      8432\n",
            "           2      0.990     0.997     0.994      7519\n",
            "           3      0.993     0.997     0.995      7831\n",
            "           4      0.994     0.991     0.993      7330\n",
            "           5      0.990     0.997     0.994      6831\n",
            "           6      0.996     0.996     0.996      7446\n",
            "           7      0.989     0.997     0.993      7922\n",
            "           8      0.999     0.985     0.992      7314\n",
            "           9      0.990     0.987     0.988      7538\n",
            "\n",
            "    accuracy                          0.994     75600\n",
            "   macro avg      0.994     0.994     0.994     75600\n",
            "weighted avg      0.994     0.994     0.994     75600\n",
            "\n",
            "\n",
            "Confusion Matrix for Fold 1:\n",
            "[[7414    0    9    0    1    4    8    1    0    0]\n",
            " [   1 8377   11    2    0    1    0   38    2    0]\n",
            " [   0    2 7495    4    0    0    1   17    0    0]\n",
            " [   2    1   10 7807    0    5    0    3    2    1]\n",
            " [   1    2    5    0 7267    0    5    5    0   45]\n",
            " [   0    0    3   14    0 6811    2    1    0    0]\n",
            " [   5    1    2    1    4   17 7416    0    0    0]\n",
            " [   0    6    7    2    5    0    0 7897    0    5]\n",
            " [   7    1   23   22    3   15   14    1 7204   24]\n",
            " [  10    1    3   10   28   27    1   21    0 7437]]\n",
            "\n",
            "Epoch 1/5\n",
            "240800/302400 [======================>.......] - ETA: 9s - loss: 0.0956 - accuracy: 0.9699"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdCMSGrGoQub",
        "colab_type": "code",
        "colab": {},
        "outputId": "ec153b75-6b70-4ea7-c471-3851a94fdcb7"
      },
      "source": [
        "lenet5_model = Pipeline([\n",
        "    ('min_max_scaler', MinMaxScaler()),\n",
        "    ('image_reshaper', ImageReshaper(shape=(-1, 28, 28, 1))),\n",
        "    ('model', KerasClassifier(build_lenet5_model, epochs=5, batch_size=32))\n",
        "])\n",
        "\n",
        "custom_lenet5_model = Pipeline([\n",
        "    ('min_max_scaler', MinMaxScaler()),\n",
        "    ('image_reshaper', ImageReshaper(shape=(-1, 28, 28, 1))),\n",
        "    ('model', KerasClassifier(build_custom_lenet5_model, epochs=20, batch_size=32))\n",
        "])\n",
        "\n",
        "\n",
        "lenet5_model.fit(X_train_combined, y_train_combined)\n",
        "# Getting the estimated probabilities for each class\n",
        "lenet5_model_predictions = lenet5_model.predict_proba(X_test)\n",
        "\n",
        "custom_lenet5_model.fit(X_train_combined, y_train_combined)\n",
        "# Getting the estimated probabilities for each class\n",
        "custom_lenet5_model_predictions = custom_lenet5_model.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "378000/378000 [==============================] - 57s 151us/step - loss: 0.0760 - accuracy: 0.9760\n",
            "Epoch 2/5\n",
            "378000/378000 [==============================] - 57s 150us/step - loss: 0.0257 - accuracy: 0.9918\n",
            "Epoch 3/5\n",
            "378000/378000 [==============================] - 57s 150us/step - loss: 0.0181 - accuracy: 0.9942\n",
            "Epoch 4/5\n",
            "378000/378000 [==============================] - 56s 149us/step - loss: 0.0143 - accuracy: 0.9955\n",
            "Epoch 5/5\n",
            "378000/378000 [==============================] - 56s 149us/step - loss: 0.0123 - accuracy: 0.9962\n",
            "Epoch 1/20\n",
            "378000/378000 [==============================] - 186s 493us/step - loss: 0.0335 - accuracy: 0.9901\n",
            "Epoch 3/20\n",
            "378000/378000 [==============================] - 189s 500us/step - loss: 0.0128 - accuracy: 0.9961\n",
            "Epoch 8/20\n",
            "378000/378000 [==============================] - 184s 488us/step - loss: 0.0058 - accuracy: 0.9981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv5sW8FmoQuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = lenet5_model_predictions + custom_lenet5_model_predictions\n",
        "\n",
        "predictions = np.argmax(predictions, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUGXg6LwoQu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Generating the submission file\n",
        "submission_df[\"Label\"] = predictions\n",
        "submission_df.to_csv('submissions.csv', index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YNhdqsDoQvC",
        "colab_type": "code",
        "colab": {},
        "outputId": "fad8e224-9b67-4bdf-f6ae-adf8bd19af0b"
      },
      "source": [
        "submission_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ImageId  Label\n",
              "0        1      2\n",
              "1        2      0\n",
              "2        3      9\n",
              "3        4      0\n",
              "4        5      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}